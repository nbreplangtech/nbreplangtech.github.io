---
layout: page
title: Call for Submissions
permalink: /
name: 1
---

### Overview

This workshop will critically analyze how language tech treats the complexity of non-binary identities and discuss potential solutions.

### Background

Recently, the advance of AI has enabled many applications based on natural language processing (NLP) technology. For example, large language models, trained on vast amounts of texts collected from books, news, and the internet, have significantly boosted the performance of language processing systems (for whom? ü§î) However, several studies (Bender et al., 2021; Blodgett et al., 2020) have pointed out significant limitations of these models.

Language models can perpetrate harms such as the cyclical erasure of non-binary gender, ethnic, sexual, etc. identities (Dev et al., 2021). Some recent works attempt to mitigate these harms by building task-specific datasets that are not restricted to binary identities and building metrics that, on extension, could potentially measure biases against more identities (Cao and Daum√© III, 2020; Rudinger et al., 2018). While such works that intentionally inject real-world or artificially-created data of non-binary people into binary datasets are well-intentioned, they could benefit from a broader perspective of harms as perceived by non-binary persons to avoid mischaracterizing non-binary identities as a single identity or perpetuating biases through non-intersectional training examples, i.e. examples that do not capture the interconnected nature of social identities (Sun et al., 2021; Crenshaw, 1989).

### Call for Submissions

Towards mitigating the aforementioned harms, we invite short research papers on the following topics:
*  critical, interdisciplinary surveys of how language technologies treat the complexity of non-binary identities and related language
* participatory approaches towards understanding the harms associated with the treatment of identities as binary in language technologies (especially non-English language technologies)
* quantitative analyses of how current language representations capture and perpetrate harms against non-binary people
* multidisciplinary perspectives on challenges that need to be acknowledged and potential solutions to more equitably encode non-binary identities, if at all possible (QueerInAI et al., 2021)

We will prioritize papers that adopt a multidisciplinary lens. In addition to the solicitation for short research papers, we will have a separate track for submissions in any media, e.g. poetry, music, art, musings, testimonials.

### Anti-Harassment Policy and Code of Conduct 

This workshop is a collaboration between [UCLA NLP](http://web.cs.ucla.edu/~kwchang/) and [Queer in AI](http://queerinai.org/). The workshop will adhere to the [ACL Anti-Harassment Policy](https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy) and [Queer in AI Code of Conduct](http://queerinai.org/code-of-conduct) to ensure a safe and inclusive space for all participants.

### References

Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT '21). Association for Computing Machinery, New York, NY, USA, 610‚Äì623. DOI:https://doi.org/10.1145/3442188.3445922

Kimberl√© Crenshaw. 1989. Demarginalizing the intersection of race and sex: A black feminist critique of antidiscrimination doctrine, feminist theory and antiracist policies. University of Chicago Legal Forum, 1989(1):139‚Äì167.

QueerInAI, Organizers of and Ashwin and William Agnew and Juan Pajaro and Arjun Subramonian. 2021. Rebuilding Trust: Queer in AI Approach to Artificial Intelligence Risk Management. Queer in AI.

Rachel Rudinger, Jason Naradowsky, Brian Leonard, and Benjamin Van Durme. 2018. Gender bias in coreference resolution. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 8‚Äì14, New Orleans, Louisiana. Association for Computational Linguistics.

Su Lin Blodgett, Solon Barocas, Hal Daum√© III, and Hanna Wallach. 2020. Language (technology) is power: A critical survey of ‚Äúbias‚Äù in NLP. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5454‚Äì5476, Online. Association for Computational Linguistics.

Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, Jeff M Phillips, and Kai-Wei Chang. 2021. Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP '21). Association for Computational Linguistics, USA.

Tony Sun, Kellie Webster, Apu Shah, William Yang Wang, and Melvin Johnson. 2021. They, them, theirs: Rewriting with gender-neutral english.

Yang Trista Cao and Hal Daum√© III. 2020. Toward gender-inclusive coreference resolution. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4568‚Äì4595, Online. Association for Computational Linguistics.
